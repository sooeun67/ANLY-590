{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fFTvLomxL48p"
   },
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gqYpW7Q1LztU"
   },
   "outputs": [],
   "source": [
    "#!pip install -q ktext\n",
    "#!pip install -q annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I9m7ds9tMYiA",
    "outputId": "edb77a25-c812-4ea8-96d4-778e6afcfe73"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from urllib.request import urlopen\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#from annoy import AnnoyIndex\n",
    "from keras import optimizers\n",
    "from keras.layers import Input, Dense, LSTM, GRU, Embedding, Lambda, BatchNormalization, Bidirectional\n",
    "from keras.models import load_model, Model\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import get_file, to_categorical\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, CSVLogger\n",
    "from ktext.preprocess import processor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iJxZnuLEMgcA"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "BXi9YCHQMkFH",
    "outputId": "53d988e8-5000-451a-d7af-9107a9724b6d"
   },
   "outputs": [],
   "source": [
    "# News Dataset\n",
    "news = pd.read_csv(\"F:/HOYA/590/Project/Data_All/articles20k_input.csv\", encoding='latin-1')\n",
    "news.columns = ['title', 'body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Dataset\n",
    "news = pd.read_csv(\"F:/HOYA/590/Project/Data_All/articles20k_input.csv\", encoding='utf-8')\n",
    "news.columns = ['title', 'body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ghX0yxW85vRA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19800, 2)\n",
      "(200, 2)\n"
     ]
    }
   ],
   "source": [
    "traindf, testdf = train_test_split(news, test_size=.010)\n",
    "print(traindf.shape)\n",
    "print(testdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "retvhM4VNrnh"
   },
   "outputs": [],
   "source": [
    "source_docs = list(traindf.body)\n",
    "target_docs = list(traindf.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XC7ktVEs6RvC"
   },
   "outputs": [],
   "source": [
    "test_source_docs = list(testdf.body)\n",
    "test_target_docs = list(testdf.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HnpRFKgve_pg"
   },
   "source": [
    "## Sequence to Sequence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "PTZO8RVpfMUk",
    "outputId": "ef930335-70cd-4001-8917-f48ab2aa1777"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source:  It has been a rough year. By now, our violence is down to a pattern, and there is a choreography to our reactions. A killer seeks out a nightclub, a church, an airport, a courthouse, a protest. Someone is shot on video, sometimes by the police, and marchers fill the streets. An attack is carried out in France, America, Turkey, Bangladesh, Lebanon, Tunisia, Nigeria, and then claimed and celebrated by a radical terror group. Our phones vibrate with news alerts. The talking heads fill air over cable news captions that shout âbreaking newsâ in red. Rumors and misinformation abound. The comments erupt on Twitter, Facebook and news sites. Journalists create multimedia stories that focus on videos, photos and graphic accounts from victims and witnesses. The experts give interviews, and the latest tools of immediacy are put to use. After thedeadly terror attack in Nice, France, The Times invited grief counselors to be interviewed on Facebook Live. Within days, attention had turned to a shooting in Baton Rouge that left three law enforcement officers dead. So, what is this doing to us?  It depends on the individual, but living in a digitally linked world where broadcasts of violence are instantaneous and almost commonplace means that many of us are becoming desensitized, Anita   a psychologist in Washington, said Friday. âWith the frequency of shootings and terror attacks there is a sense of anxiety thatâs building in people,â she said, âa sense of vulnerability and powerlessness. â Dr. Smith added: âThere is a heightened alarm, but there can also be some desensitization thatâs happening. â The constant stream of news on social media can also be traumatic. A team of researchers at the University of Bradford in England told a British psychology conference last year that exposure to violent imagery on social media can cause symptoms that are similar to   stress disorder, defined as a persistent emotional reaction to a traumatic event that severely impairs oneâs life. In an analysis conducted by the Bradford researchers, 189 participants were shown images and provided with stories of violent events, including the Sept. 11 attacks, school shootings and suicide bombings. The researchersâ analysis showed that 22 percent of those who participated were significantly affected by what they saw. The study also found that people who view violent events more often were more affected than people who saw them less frequently, and that people who described themselves as extroverts with outgoing personalities were at a higher risk to be disturbed by the images. What can we do about it?  The   advice hasnât changed. It is natural to want to follow along with incremental updates on social media and in the news. But itâs important to know that this can heighten your anxiety. Anne Marie Albano, a clinical psychologist and the director of the Columbia University Clinic for Anxiety and Related Disorders, said in an interview after the 2015 Paris attacks that it might be a good idea to limit your exposure to social media. Designating times to plug into the news  â   checking Twitter in the morning over coffee, but not listening to the radio while driving your kids to school, for instance  â   can help you manage anxiety if you are feeling stressed. âThis will help you balance a realistic and credible threat with information that is sensationalized,â Dr. Albano said, âor a rush to report something or talk about something that doesnât have the impact that you would think it has. â If youâre feeling anxiety about a possible attack, compare your fear with the facts.  When you fear the worst, itâs hard to remember that, say, a flight or a train ride has extraordinarily high odds of being safe. But you have to try. Humans are bad at assessing risk, Martin Seif, a psychologist who specializes in treating anxiety disorders and the fear of flying, said in an interview late last year. âEvery single   technique is based on the premise that your reaction is out of proportionâ to the likelihood of danger, Dr. Seif said. Also, remember to take a breath.  A guide to dealing with terrorism released by the Federal Bureau of Investigation encourages closing your eyes and taking deep breaths to feel calmer. Taking a walk or talking to a close friend can also help. The guide also recommends avoiding alcohol and drugs, exercising regularly and eating healthy foods  â   basic   guidelines that help reduce stress. Make sure you have a plan to contact your family if something happens, especially if cellular networks are overloaded or transportation is disrupted, but remember that you most likely will not need it, experts say. If you have children, the American Psychological Association recommends asking them how they are feeling about the news. Keep in mind that it is possible for children to be influenced by news reports and the adult conversations around them. Lastly, keep your daily routine.  Dr. Albano said that a primary worry in the field of psychology is people âgoing out of their way to be so safe that it shrinks their world. â âTerrorists thrive on this kind of thing,â she added. âThey want to see the population change their practices. â Going out of your way to avoid interacting with strangers  â   by refusing to take mass transit, for example  â   can stoke fear and anxiety in children, she said. The best way to help children cope with acts of violence is to start by listening to them, Sean Rogers, a psychotherapist who works with children and teenagers, told The Times on his Facebook Live appearance. âListening is curative,â he said. âIt is the basis of all therapies. â\n",
      "target:  What Is a Constant Cycle of Violent News Doing to Us? - The New York Times\n"
     ]
    }
   ],
   "source": [
    "print('source: ', source_docs[4])\n",
    "print('target: ', target_docs[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BbeAEzT2fZ1x"
   },
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "mGQFh2nAfhOC",
    "outputId": "917cd972-60eb-409d-82e3-2f61127c62f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:....tokenizing data\n",
      "WARNING:root:Setting maximum document length to 920 based upon hueristic of 0.7 percentile.\n",
      " See full histogram by insepecting the `document_length_stats` attribute.\n",
      "WARNING:root:(1/2) done. 115 sec\n",
      "WARNING:root:....building corpus\n",
      "WARNING:root:(2/2) done. 5 sec\n",
      "WARNING:root:Finished parsing 19,800 documents.\n",
      "WARNING:root:...fit is finished, beginning transform\n",
      "WARNING:root:...padding data\n",
      "WARNING:root:done. 3 sec\n"
     ]
    }
   ],
   "source": [
    "source_proc = processor(hueristic_pct_padding=.7, keep_n=8000)\n",
    "source_vecs = source_proc.fit_transform(source_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "original string:\n",
      " PHILADELPHIA  â   Forty times, city or state governments had proposed taxes on sugary soft drinks, failing each time. Then, in 2014, liberal Berkeley, Calif. passed such a tax, but most people saw it as an aberration. Several measures, including one in New York, never won much support. But on Thursday, a measure to tax sweetened drinks passed in Philadelphia, one of the countryâs largest cities  â   and also one of its poorest. Indeed, raising revenue was the winning argument in Philadelphia. Jim Kenney, the mayor, took a different tack from that of politicians who have tried and failed to pass   taxes. He didnât talk about the tax as a   measure designed to discourage   soft drinks. And he didnât promise to earmark the proceeds for health programs. Instead, he cast the soft drink industry as a tantalizing revenue source that could be tapped to fund popular city programs, including universal prekindergarten. âThis is the beginning of a process of changing the narrative of poverty in our city,â he said in a news conference after the vote. The advocates who have pushed for the policy say the victory is a sign of growing public acceptance of soft drink taxes and presages more such measures around the country. Though city officials didnât talk much about the health consequences of soda, experts said that sugary drinksâ increasingly bad reputation made it an appropriate political target. âIf we go five years ahead and look back, I think this is going to be a watershed moment,â said Jim Krieger, executive director at Healthy Food America, an organization that is helping cities around the country that are considering soda taxes. âThis is going to really provide momentum. â San Francisco Oakland, Calif. and Boulder, Colo. are considering soft drink taxes this year. Mr. Krieger said the list of interested cities included some that were as large and diverse as Philadelphia. Mr. Kenney said he hadnât yet spoken directly with officials from other cities, but he had advice for them. âTie your efforts to tangible initiatives that people care about,â he said in his news conference. âWhen it comes up, acknowledge that it is a good thing to drink less   beverages, but tie it to things that people care about. â The Philadelphia tax of 1. 5 cents an ounce will apply to all sugary or artificially sweetened drinks sold by distributors in the city. It is expected to increase prices  â   the tax is about 30 cents for a   drink, or $2. 16 for a  . If passed on to consumers, the increase is expected to substantially reduce sales of sweetened drinks. The city finance department estimates it will raise $91 million a year. Sugary drinks have been linked to health problems, including obesity, diabetes and tooth decay, but the public health effects of the taxes are still unclear. Philadelphia is likely to become the site of public health research. Thomas Farley, the cityâs health commissioner, said the city had already planned to measure the taxâs immediate effects on sales.   studies will measure any impact on obesity. The soft drink industry and its allies, including the Teamsters union and local grocers, spent nearly $5 million on lobbying and advertising to fight the tax in Philadelphia. They held rallies and demonstrations downtown and ran   ads on television and the radio, right up until Thursdayâs final vote. They branded the drinks tax measure a âgrocery tax,â suggesting that more food products were next. The soda industry has argued that Philadelphiaâs politics are unusual and that the vote here canât be seen as predictive. The American Beverage Association, a trade group, has vowed to fight the measure in the courts. âItâs still a bad idea,â said Lauren Kane, a spokeswoman for the group. âPeople still oppose it. Nothing has changed. â Thursday, the industry and its allies vented frustration. Daniel Grace, the secretary and treasurer of the Teamsters local, said advocates had âsnookered City Council,â and he described the tax as a âbrazen cash grab from one industry. â The promise of prekindergarten energized the cityâs education advocates, who joined with public health advocates. The coalition spent about $2 million on advertisements, according to Kevin Feeley, a spokesman for Philadelphians for a Fair Future, a group supporting the tax. That total included $1. 6 million in donations from Michael R. Bloomberg, the former New York mayor, who has long supported soda taxes. But Mr. Kenneyâs focus on revenue also allowed him to help cut deals with skeptical city councilors. Ultimately, the soft drink tax revenue wonât pay just for prekindergarten, but for a host of city programs, reflecting the priorities of the council members who voted for it. \n",
      "\n",
      "after pre-processing:\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0 2067    1  156  155   43   79 1812   38 1470\n",
      " 1359   12    1 4314 5197 2433  325   81  127    7    9  996 2123 2886\n",
      " 1006  188    5  426   32   95   52  598   15   19   31    1  254 1567\n",
      "  167   48    7   54  153  198  287  146  206   32   12  324    5 1426\n",
      "    3  426    1 5197 1006    7 2067   48    4    2  116   10  973  820\n",
      "    6   64   48    4   63 7528 1533 1965 2012   16    2 1287 1655    7\n",
      " 2067 2261    1    2  903  235    5  364    1   26    8    4 1220   35\n",
      "   25  653    6  768    3 1181 1359   14  321   45  485   41    2  426\n",
      "   19    5 1426 1745    3    1 4314 5197    6   14  321   45 1440    3\n",
      "    1    2 7570   11  215 1051  460   14 1381    2 4314 3570  595   19\n",
      "    5    1 2012 1383    8   84   30 6211    3 1110  794  155 1051  167\n",
      " 3635    1   36   13    2 1190    4    5  497    4 2053    2 2441    4\n",
      " 2553    7   77  155   14   17    7    5   82  594   59    2  270    2\n",
      " 2062   35   25 1553   11    2  231  129    2  749   13    5  956    4\n",
      "  930  166 4126    4 4314 3570 1359    6    1   51  188 1567  192    2\n",
      "  116  262  155  160  321   45  485  146   41    2  215 2149    4 7454\n",
      "  976   17    8    1 5197 1250  634 2371  119   15   31 2528  148 1209\n",
      "   60   37  191  379   90 1025    6  291  133   21  121   36   13  115\n",
      "    3   30    5    1  675   17 2261    1  267  293   23 2594  714  195\n",
      "   31  559    8   13 1497  820  192    2  116    8   33 2209 7454 1359\n",
      "   36   13  115    3  237  811 4261  651 1389 3945 2886    6    1    1\n",
      "   33 2209 4314 3570 1359   36   97   20    1   17    2  611    4 2148\n",
      "  820  791   71    8   46   19  525    6 3131   19 2067   20    1   17\n",
      "   14 4041   45  299 2646 1028   18  160   26   73  820   32   14   38\n",
      " 2110   11   75 4235  147  613    3    1 4981    8   52  285   41   14\n",
      "   17    7   22   82  594   56   15  582   67 4069    8   15   13    5\n",
      "  199  375    3 3570  305    1   32 4235   15    3  274    8   52  285\n",
      "   41    2 2067  426    4    9    9 6413   31    1   50 2398    3   62\n",
      "    1   43    1    1 5197 1371   24    1    7    2  155   15   13  591\n",
      "    3  779 1645    2  426   13   41    9 6413   11    5 3570   43  101\n",
      "    9    9   11    5   60 1006   12    3 1966    2  779   13  591    3\n",
      " 6517 1816 1246    4    1 5197    2  155 2106  204 3222   15   50 1372\n",
      "  101    9  172    5   97    1 5197   25   49 2214    3  215  773  167\n",
      " 7293 6440    6    1    1   32    2  166  215 2124    4    2 1359   33\n",
      "  152 1957 2067   13  407    3  307    2  912    4  166  215  576 1447\n",
      "    1    2  155   10  215 2618   17    2  155   38  322  669    3 1426\n",
      "    2  426   10 2446 2124   12 1246 1265   50 1426  117 1301   12 7293\n",
      "    2 4314 3570  595    6   63 1156  167    2    1  443    6  372    1\n",
      "  673  431  101    9  172   12 4027    6 2204    3  514    2  426    7\n",
      " 2067   34  521 3091    6 5211 3115    6 1164 2598   12  692    6    2\n",
      "  742  185   67  350  324   10  698  270   34 7348    2 5197  426 1426\n",
      "    5 5441  426 2270    8   51  714 1542   46  239    2 7454  595   29\n",
      " 1047    8 2067   10  536   33 2120    6    8    2  270  139   66   45\n",
      "   30  378   19    1    2  100    1 1204    5  449  178   29 2514    3\n",
      "  514    2 1426    7    2 1863   15   10  152    5  634  575   17 7786\n",
      "    1    5 1919   11    2  178   52  152 2727   15  479   29 1084  324\n",
      "    2  595    6   63 1156    1 3512 1987 5042    2  335    6    1    4\n",
      "    2    1  372   17 2062   38    1  155  747    6   14  571    2  426\n",
      "   19    5    1 1439 5532   26   48  595    2 1440    4    1    1    2\n",
      "  155   10  639 2062   35 1123   18  166  215 2062    2 1503  673   41\n",
      "  101    9  172   12    1  144    3 2808    1    5  756   11    1   11\n",
      "    5 1429  505    5  178 1520    2  426    8  964  791  101    9    9\n",
      "  172    7 2709   26  691 1112 3223    2  150   54  153  903   35   29\n",
      "  201 1186 7454 1359   32   20    1   10  906   12 2012   64  736   69\n",
      "    3  241  860 1449   18 3763  155    1 1403    2 4314 3570  426 2012\n",
      "  287   45  490   78   11    1   32   11    5  635    4  155 1051 6281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2 3197    4    2  747  240   35  970   11   15] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\noriginal string:\\n', source_docs[0], '\\n')\n",
    "print('after pre-processing:\\n', source_vecs[0], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from ktext.preprocess import processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "7RI9G3LffosC",
    "outputId": "c8222b0b-e6fd-4479-d580-5efba2c6af31"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:....tokenizing data\n",
      "WARNING:root:Setting maximum document length to 15 based upon hueristic of 0.7 percentile.\n",
      " See full histogram by insepecting the `document_length_stats` attribute.\n",
      "WARNING:root:(1/2) done. 10 sec\n",
      "WARNING:root:....building corpus\n",
      "WARNING:root:(2/2) done. 0 sec\n",
      "WARNING:root:Finished parsing 19,800 documents.\n",
      "WARNING:root:...fit is finished, beginning transform\n",
      "WARNING:root:...padding data\n",
      "WARNING:root:done. 0 sec\n"
     ]
    }
   ],
   "source": [
    "target_proc = processor(append_indicators=True, hueristic_pct_padding=.7, keep_n=4500, padding ='post')\n",
    "target_vecs = target_proc.fit_transform(target_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oy3oV8roftWq"
   },
   "outputs": [],
   "source": [
    "encoder_input_data = source_vecs\n",
    "encoder_seq_len = encoder_input_data.shape[1]\n",
    "\n",
    "decoder_input_data = target_vecs[:, :-1]\n",
    "decoder_target_data = target_vecs[:, 1:]\n",
    "\n",
    "num_encoder_tokens = max(source_proc.id2token.keys()) + 1\n",
    "num_decoder_tokens = max(target_proc.id2token.keys()) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nqacQTAkkdMH"
   },
   "source": [
    "### Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cpt05-lS2aVL"
   },
   "outputs": [],
   "source": [
    "word_emb_dim=512\n",
    "hidden_state_dim=1024\n",
    "encoder_seq_len=encoder_seq_len\n",
    "num_encoder_tokens=num_encoder_tokens\n",
    "num_decoder_tokens=num_decoder_tokens\n",
    "\n",
    "#arbitrarly set latent dimension for embedding and hidden units\n",
    "latent_dim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kBNyIbF-fux7"
   },
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(encoder_seq_len,), name='Encoder-Input')\n",
    "\n",
    "# Word embeding for encoder (ex: Issue Body)\n",
    "x = Embedding(num_encoder_tokens, latent_dim, name='Body-Word-Embedding', mask_zero=False)(encoder_inputs)\n",
    "x = BatchNormalization(name='Encoder-Batchnorm-1')(x)\n",
    "\n",
    "# Intermediate GRU layer (optional)\n",
    "#x = GRU(latent_dim, name='Encoder-Intermediate-GRU', return_sequences=True)(x)\n",
    "#x = BatchNormalization(name='Encoder-Batchnorm-2')(x)\n",
    "\n",
    "# We do not need the `encoder_output` just the hidden state.\n",
    "_, state_h = GRU(latent_dim, return_state=True, name='Encoder-Last-GRU', return_sequences=True)(x)\n",
    "\n",
    "# Encapsulate the encoder as a separate entity so we can just \n",
    "#  encode without decoding if we want to.\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=state_h, name='Encoder-Model')\n",
    "\n",
    "seq2seq_encoder_out = encoder_model(encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "_UKrSJPJkpLx",
    "outputId": "8124380f-38b5-4a1c-f2c1-162196ca590f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Encoder-Input (InputLayer)   (None, 920)               0         \n",
      "_________________________________________________________________\n",
      "Body-Word-Embedding (Embeddi (None, 920, 512)          4097024   \n",
      "_________________________________________________________________\n",
      "Encoder-Batchnorm-1 (BatchNo (None, 920, 512)          2048      \n",
      "_________________________________________________________________\n",
      "Encoder-Last-GRU (GRU)       [(None, 920, 512), (None, 1574400   \n",
      "=================================================================\n",
      "Total params: 5,673,472\n",
      "Trainable params: 5,672,448\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4dZTInSukw6R"
   },
   "source": [
    "### Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DWMKyVE0kwG3"
   },
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,), name='Decoder-Input')  # for teacher forcing\n",
    "\n",
    "# Word Embedding For Decoder (ex: Issue Titles)\n",
    "dec_emb = Embedding(num_decoder_tokens, latent_dim, name='Decoder-Word-Embedding', mask_zero=False)(decoder_inputs)\n",
    "dec_bn = BatchNormalization(name='Decoder-Batchnorm-1')(dec_emb)\n",
    "\n",
    "# Set up the decoder, using `decoder_state_input` as initial state.\n",
    "decoder_gru = GRU(latent_dim, return_state=True, return_sequences=True, name='Decoder-GRU')\n",
    "decoder_gru_output, _ = decoder_gru(dec_bn, initial_state=seq2seq_encoder_out)\n",
    "x = BatchNormalization(name='Decoder-Batchnorm-2')(decoder_gru_output)\n",
    "\n",
    "# Dense layer for prediction\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='Final-Output-Dense')\n",
    "decoder_outputs = decoder_dense(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NYGAqYdBlAeo"
   },
   "source": [
    "### Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VuVxckMrlEYP"
   },
   "outputs": [],
   "source": [
    "seq2seq_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "seq2seq_model.compile(optimizer=optimizers.Nadam(lr=0.001), loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "yewE_ctBlI7w",
    "outputId": "cd37d5c3-bd2e-4b4b-97bb-aad139a955b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Decoder-Input (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-Word-Embedding (Embeddi (None, None, 512)    2305024     Decoder-Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Input (InputLayer)      (None, 920)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-Batchnorm-1 (BatchNorma (None, None, 512)    2048        Decoder-Word-Embedding[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Model (Model)           (None, 512)          5673472     Encoder-Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-GRU (GRU)               [(None, None, 512),  1574400     Decoder-Batchnorm-1[0][0]        \n",
      "                                                                 Encoder-Model[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-Batchnorm-2 (BatchNorma (None, None, 512)    2048        Decoder-GRU[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Final-Output-Dense (Dense)      (None, None, 4502)   2309526     Decoder-Batchnorm-2[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 11,866,518\n",
      "Trainable params: 11,863,446\n",
      "Non-trainable params: 3,072\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq2seq_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KEmiGZrslIPg"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "cWkAUaRLv9os",
    "outputId": "0b18d3bb-9e7f-4f0f-b35f-7b8f8ba288a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17424 samples, validate on 2376 samples\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1200,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[Node: Encoder-Model/Encoder-Last-GRU/while/mul_1 = Mul[T=DT_FLOAT, _class=[\"loc:@train...ad/Reshape\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Encoder-Model/Encoder-Last-GRU/while/mul/x, Encoder-Model/Encoder-Last-GRU/while/add_3)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-d6baa1b3cf68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m           validation_split=0.12, callbacks=[csv_logger, model_checkpoint])\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n\u001b[1;32m-> 1454\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1200,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[Node: Encoder-Model/Encoder-Last-GRU/while/mul_1 = Mul[T=DT_FLOAT, _class=[\"loc:@train...ad/Reshape\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Encoder-Model/Encoder-Last-GRU/while/mul/x, Encoder-Model/Encoder-Last-GRU/while/add_3)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "script_name_base = 'seq2seq_v2'\n",
    "csv_logger = CSVLogger('{:}.log'.format(script_name_base))\n",
    "model_checkpoint = ModelCheckpoint('{:}.epoch{{epoch:02d}}-val{{val_loss:.5f}}.hdf5'.format(script_name_base),\n",
    "                                   save_best_only=True)\n",
    "\n",
    "batch_size = 1200\n",
    "epochs = 7\n",
    "history = seq2seq_model.fit([encoder_input_data, decoder_input_data], np.expand_dims(decoder_target_data, -1),\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.12, callbacks=[csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "jdPMVVl23FCy",
    "outputId": "d159abd5-4a0f-4f3c-d363-ce39724105d1"
   },
   "outputs": [],
   "source": [
    "#save model\n",
    "seq2seq_model.save('seq2seq_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1lbdGPHE0v-B"
   },
   "source": [
    "### Extract Encoder and Decoder Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mQt33kZq3a8x"
   },
   "outputs": [],
   "source": [
    "def extract_decoder_model(model):\n",
    "    latent_dim = model.get_layer('Encoder-Model').output_shape[-1]\n",
    "    decoder_inputs = model.get_layer('Decoder-Input').input\n",
    "    dec_emb = model.get_layer('Decoder-Word-Embedding')(decoder_inputs)\n",
    "    dec_bn = model.get_layer('Decoder-Batchnorm-1')(dec_emb)\n",
    "    gru_inference_state_input = Input(shape=(latent_dim,), name='hidden_state_input')\n",
    "    gru_out, gru_state_out = model.get_layer('Decoder-GRU')([dec_bn, gru_inference_state_input])\n",
    "    dec_bn2 = model.get_layer('Decoder-Batchnorm-2')(gru_out)\n",
    "    dense_out = model.get_layer('Final-Output-Dense')(dec_bn2)\n",
    "    decoder_model = Model([decoder_inputs, gru_inference_state_input], [dense_out, gru_state_out])\n",
    "    return decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "WMjjbtS73ccS",
    "outputId": "70a2719c-f0ad-4bfe-df9a-145ac0f86440"
   },
   "outputs": [],
   "source": [
    "encoder_model = seq2seq_model.get_layer('Encoder-Model')\n",
    "for layer in encoder_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "decoder_model = extract_decoder_model(seq2seq_model)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "F3OQxFABMVlr",
    "outputId": "56f6d9c7-6fb0-4c9d-c8f7-13be432eb639"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZFdwR6UR0v-L"
   },
   "source": [
    "### Predict code descriptions using the trained sequence-to-sequence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121842
    },
    "colab_type": "code",
    "id": "lXTp4dEW3h5Z",
    "outputId": "984e75fc-cf5f-45ee-d36f-542b49265d35"
   },
   "outputs": [],
   "source": [
    "col_names =  ['body', 'actual_title', 'generated_title']\n",
    "resultDF  = pd.DataFrame(columns = col_names)\n",
    "test_idx = list(range(1, len(test_source_docs)))\n",
    "max_len = target_proc.padding_maxlen\n",
    "\n",
    "for i in test_idx:\n",
    "  \n",
    "  raw_input_text = test_source_docs[i]\n",
    "  raw_tokenized = source_proc.transform([raw_input_text])\n",
    "  encoding = encoder_model.predict(raw_tokenized)\n",
    "  original_encoding = encoding\n",
    "  state_value = np.array(target_proc.token2id['_start_']).reshape(1, 1)\n",
    "  \n",
    "  decoded_sentence = []\n",
    "  stop_condition = False\n",
    "  while not stop_condition:\n",
    "    preds, st = decoder_model.predict([state_value, encoding])\n",
    "    pred_idx = np.argmax(preds[:, :, 2:]) + 2\n",
    "    pred_word_str = target_proc.id2token[pred_idx]\n",
    "\n",
    "    if pred_word_str == '_end_' or len(decoded_sentence) >= max_len:\n",
    "        stop_condition = True\n",
    "        break\n",
    "    decoded_sentence.append(pred_word_str)\n",
    "    \n",
    "    # update the decoder for the next word\n",
    "    encoding = st\n",
    "    state_value = np.array(pred_idx).reshape(1, 1)\n",
    "    \n",
    "  pred_sent = ' '.join(decoded_sentence)\n",
    "    \n",
    "  \n",
    "  # print\n",
    "  print('\\n\\n==============================================')\n",
    "  print(f'============== News # {i} =================\\n')\n",
    "  print('News Body:\\n------------------------\\n', raw_input_text)\n",
    "  print('\\nNews Headline:\\n------------------------\\n', test_target_docs[i])\n",
    "  print('\\nMachine-generated Headline:\\n------------------------\\n', pred_sent)\n",
    "    \n",
    "    \n",
    "  # append to dataframe\n",
    "  tmpDF = pd.DataFrame({\"body\": [raw_input_text], \n",
    "                        \"actual_title\": [test_target_docs[i]], \n",
    "                        \"generated_title\": [pred_sent]})\n",
    "  resultDF = pd.concat([resultDF, tmpDF], ignore_index=True)\n",
    "\n",
    "  \n",
    "resultDF.to_csv('News.csv', encoding='latin-1')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Text_Summarization_V2.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
